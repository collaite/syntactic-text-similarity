{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d0926d-0b9a-4a82-8d43-cbf1f63b2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# input data files\n",
    "data_files = ['results-syn-hamming', 'results-syn-leven', 'results-syn-jaro', 'results-syn-lcsstr', 'results-syn-sorensen', 'results-syn-jaccard', 'results-syn-tversky']\n",
    "\n",
    "# output samples (dataframes) for each input data file\n",
    "composite_samples = []\n",
    "\n",
    "# define function to calculate sample size and proportion using Slovin's formula\n",
    "def get_sample_size_and_proportion(population_df, error_tolerance, stratification_variable):\n",
    "    # Use Slovin's formula for sample size: n = N / (1 + Ne2)\n",
    "    sample_size = len(population_df) / (1 + (len(population_df)*(error_tolerance ** 2)))\n",
    "    sample_proportion = sample_size/len(population_df)\n",
    "    print()\n",
    "    print('sample size: ', sample_size)\n",
    "    print()\n",
    "    # print('sample proportion: ', sample_proportion)\n",
    "    return {'size' : sample_size, 'proportion' : sample_proportion}\n",
    "\n",
    "def get_sample(population_df, error_tolerance, stratification_variable):\n",
    "    # remove all rows that have perfectly matching scores of 1 (no need for human judgement for exact matches)\n",
    "    population_df = population_df[population_df['similarity_score'] < 1.0]\n",
    "    # partition data into low, medium and high context sizes \n",
    "    population_df_low_context_size = population_df[population_df['context_size'] <= 3]\n",
    "    population_df_medium_context_size = population_df.loc[(population_df['context_size'] > 3) & (population_df['context_size'] <= 6)]\n",
    "    population_df_high_context_size = population_df[population_df['context_size'] > 6]\n",
    "    \n",
    "    print(len(population_df_low_context_size))\n",
    "    print(len(population_df_medium_context_size))\n",
    "    print(len(population_df_high_context_size))\n",
    "    print()\n",
    "    \n",
    "    # remove 't' anomaly\n",
    "    population_df_low_context_size = population_df_low_context_size[population_df_low_context_size['source_token'] != 't']\n",
    "    population_df_medium_context_size = population_df_medium_context_size[population_df_medium_context_size['source_token'] != 't']\n",
    "    population_df_high_context_size = population_df_high_context_size[population_df_high_context_size['source_token'] != 't']\n",
    "    \n",
    "    print(len(population_df_low_context_size))\n",
    "    print(len(population_df_medium_context_size))\n",
    "    print(len(population_df_high_context_size))\n",
    "    print()\n",
    "    \n",
    "    # create a column with both pairs of contexts in a single string (to calculate number of unique pairs)\n",
    "    population_df_low_context_size[\"context_pair_to_compare\"] = population_df_low_context_size[\"source_context_inline\"] + ' | ' + population_df_low_context_size[\"target_context_inline\"]\n",
    "    population_df_medium_context_size[\"context_pair_to_compare\"] = population_df_medium_context_size[\"source_context_inline\"] + ' | ' + population_df_medium_context_size[\"target_context_inline\"]\n",
    "    population_df_high_context_size[\"context_pair_to_compare\"] = population_df_high_context_size[\"source_context_inline\"] + ' | ' + population_df_high_context_size[\"target_context_inline\"]\n",
    "\n",
    "    print(population_df_low_context_size['context_pair_to_compare'].nunique())\n",
    "    print(population_df_medium_context_size['context_pair_to_compare'].nunique())\n",
    "    print(population_df_high_context_size['context_pair_to_compare'].nunique())\n",
    "    \n",
    "    # Perform stratified sampling according to similarity score\n",
    "    low_context_size_sample_stats = get_sample_size_and_proportion(population_df_low_context_size, error_tolerance, stratification_variable)\n",
    "    low_context_size_sample = population_df_low_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(frac=low_context_size_sample_stats['proportion']))\n",
    "    # low_context_size_sample = population_df_low_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(1))\n",
    "    medium_context_size_sample_stats = get_sample_size_and_proportion(population_df_medium_context_size, error_tolerance, stratification_variable)\n",
    "    medium_context_size_sample = population_df_medium_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(frac=medium_context_size_sample_stats['proportion']))\n",
    "    # medium_context_size_sample = population_df_medium_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(1))\n",
    "    high_context_size_sample_stats = get_sample_size_and_proportion(population_df_high_context_size, error_tolerance, stratification_variable)\n",
    "    high_context_size_sample = population_df_high_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(frac=high_context_size_sample_stats['proportion']))\n",
    "    # high_context_size_sample = population_df_high_context_size.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(1))\n",
    "\n",
    "    # Concatenate samples (for low, medium and high context sizes) together\n",
    "    all_samples = []\n",
    "    all_samples.append(low_context_size_sample)\n",
    "    all_samples.append(medium_context_size_sample)\n",
    "    all_samples.append(high_context_size_sample)\n",
    "    \n",
    "    return pd.concat(all_samples, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d622f5b8-cb11-49cc-b447-4c1d6e947480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cochran's formula (90% confidence gives very similar results to Slovin's 80% confidence)\n",
    "# e = 0.1\n",
    "# z = 1.645\n",
    "# p = 0.5\n",
    "# q = 1 - p\n",
    "# print(q)\n",
    "\n",
    "# n = ((z ** 2) * p * q) / (e ** 2)\n",
    "\n",
    "# big_N = 50000\n",
    "\n",
    "# # final sample size (Cochran)\n",
    "# n_final = n / (1 + ((n - 1)/big_N))\n",
    "# n_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f386a90-2df9-45d8-94b8-c200d9244a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results-syn-hamming\n",
      "\n",
      "16484\n",
      "21187\n",
      "30492\n",
      "\n",
      "16412\n",
      "21106\n",
      "30384\n",
      "\n",
      "8760\n",
      "13944\n",
      "22824\n",
      "\n",
      "sample size:  44.324411915629135\n",
      "\n",
      "\n",
      "sample size:  44.35105119934438\n",
      "\n",
      "\n",
      "sample size:  44.37952792708577\n",
      "\n",
      "results-syn-leven\n",
      "\n",
      "16484\n",
      "21187\n",
      "30492\n",
      "\n",
      "16412\n",
      "21106\n",
      "30384\n",
      "\n",
      "8760\n",
      "13944\n",
      "22824\n",
      "\n",
      "sample size:  44.324411915629135\n",
      "\n",
      "\n",
      "sample size:  44.35105119934438\n",
      "\n",
      "\n",
      "sample size:  44.37952792708577\n",
      "\n",
      "results-syn-jaro\n",
      "\n",
      "16484\n",
      "21187\n",
      "30492\n",
      "\n",
      "16412\n",
      "21106\n",
      "30384\n",
      "\n",
      "8760\n",
      "13944\n",
      "22824\n",
      "\n",
      "sample size:  44.324411915629135\n",
      "\n",
      "\n",
      "sample size:  44.35105119934438\n",
      "\n",
      "\n",
      "sample size:  44.37952792708577\n",
      "\n",
      "results-syn-lcsstr\n",
      "\n",
      "16484\n",
      "21187\n",
      "30492\n",
      "\n",
      "16412\n",
      "21106\n",
      "30384\n",
      "\n",
      "8760\n",
      "13944\n",
      "22824\n",
      "\n",
      "sample size:  44.324411915629135\n",
      "\n",
      "\n",
      "sample size:  44.35105119934438\n",
      "\n",
      "\n",
      "sample size:  44.37952792708577\n",
      "\n",
      "results-syn-sorensen\n",
      "\n",
      "16437\n",
      "21165\n",
      "30471\n",
      "\n",
      "16365\n",
      "21084\n",
      "30363\n",
      "\n",
      "8734\n",
      "13936\n",
      "22815\n",
      "\n",
      "sample size:  44.32406811795376\n",
      "\n",
      "\n",
      "sample size:  44.350953953596\n",
      "\n",
      "\n",
      "sample size:  44.379483094417665\n",
      "\n",
      "results-syn-jaccard\n",
      "\n",
      "16437\n",
      "21165\n",
      "30471\n",
      "\n",
      "16365\n",
      "21084\n",
      "30363\n",
      "\n",
      "8734\n",
      "13936\n",
      "22815\n",
      "\n",
      "sample size:  44.32406811795376\n",
      "\n",
      "\n",
      "sample size:  44.350953953596\n",
      "\n",
      "\n",
      "sample size:  44.379483094417665\n",
      "\n",
      "results-syn-tversky\n",
      "\n",
      "16437\n",
      "21165\n",
      "30471\n",
      "\n",
      "16365\n",
      "21084\n",
      "30363\n",
      "\n",
      "8734\n",
      "13936\n",
      "22815\n",
      "\n",
      "sample size:  44.32406811795376\n",
      "\n",
      "\n",
      "sample size:  44.350953953596\n",
      "\n",
      "\n",
      "sample size:  44.379483094417665\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_token</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>context_size</th>\n",
       "      <th>source_context_words</th>\n",
       "      <th>source_context_words_nstopw</th>\n",
       "      <th>source_context_inline</th>\n",
       "      <th>source_context_inline_nstopw</th>\n",
       "      <th>source_context_span</th>\n",
       "      <th>target_context_words</th>\n",
       "      <th>target_context_words_nstopw</th>\n",
       "      <th>target_context_inline</th>\n",
       "      <th>target_context_inline_nstopw</th>\n",
       "      <th>target_context_span</th>\n",
       "      <th>similarity_metric</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>context_pair_to_compare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greta</td>\n",
       "      <td>w1</td>\n",
       "      <td>w4</td>\n",
       "      <td>3</td>\n",
       "      <td>['eerlijk', 'interieur', 'van', 'brenns', 'hui...</td>\n",
       "      <td>['eerlijk', 'interieur', 'brenns', 'huis']</td>\n",
       "      <td>eerlijk interieur van greta brenns huis daar</td>\n",
       "      <td>['eerlijk', 'interieur', 'greta', 'brenns', 'h...</td>\n",
       "      <td>[2533, 5]</td>\n",
       "      <td>['de', 'rol', 'van', 'brenn', 'vertolkte', 'sp...</td>\n",
       "      <td>['rol', 'brenn', 'vertolkte', 'speciale']</td>\n",
       "      <td>de rol van greta brenn vertolkte speciale</td>\n",
       "      <td>['rol', 'greta', 'brenn', 'vertolkte', 'specia...</td>\n",
       "      <td>[2954, 5]</td>\n",
       "      <td>hamming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eerlijk interieur van greta brenns huis daar |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>publiek</td>\n",
       "      <td>w1</td>\n",
       "      <td>w3</td>\n",
       "      <td>3</td>\n",
       "      <td>['heeft', 'omdat', 'uw', 'haar', 'niet', 'aans...</td>\n",
       "      <td>['aanstond']</td>\n",
       "      <td>heeft omdat uw publiek haar niet aanstond</td>\n",
       "      <td>['publiek', 'aanstond']</td>\n",
       "      <td>[2701, 7]</td>\n",
       "      <td>['ik', 'ga', 'het', 'verwittigen', 'dar', 'er']</td>\n",
       "      <td>['ga', 'verwittigen', 'dar']</td>\n",
       "      <td>ik ga het publiek verwittigen dar er</td>\n",
       "      <td>['ga', 'publiek', 'verwittigen', 'dar']</td>\n",
       "      <td>[2724, 7]</td>\n",
       "      <td>hamming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>heeft omdat uw publiek haar niet aanstond | ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>versiering</td>\n",
       "      <td>w1</td>\n",
       "      <td>w3</td>\n",
       "      <td>3</td>\n",
       "      <td>['en', 'tevens', 'alle', 'vermijdt', 'want', '...</td>\n",
       "      <td>['tevens', 'vermijdt']</td>\n",
       "      <td>en tevens alle versiering vermijdt want die</td>\n",
       "      <td>['tevens', 'versiering', 'vermijdt']</td>\n",
       "      <td>[1326, 10]</td>\n",
       "      <td>['prijkten', 'als', 'goedkoope', 'en', 'ter', ...</td>\n",
       "      <td>['prijkten', 'goedkoope', 'bevordering']</td>\n",
       "      <td>prijkten als goedkoope versiering en ter bevor...</td>\n",
       "      <td>['prijkten', 'goedkoope', 'versiering', 'bevor...</td>\n",
       "      <td>[1576, 10]</td>\n",
       "      <td>hamming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en tevens alle versiering vermijdt want die | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film</td>\n",
       "      <td>w1</td>\n",
       "      <td>w2</td>\n",
       "      <td>1</td>\n",
       "      <td>['sprekende', 'maar']</td>\n",
       "      <td>['sprekende']</td>\n",
       "      <td>sprekende film maar</td>\n",
       "      <td>['sprekende', 'film']</td>\n",
       "      <td>[184, 4]</td>\n",
       "      <td>['de', 'ziet']</td>\n",
       "      <td>['ziet']</td>\n",
       "      <td>de film ziet</td>\n",
       "      <td>['film', 'ziet']</td>\n",
       "      <td>[2920, 4]</td>\n",
       "      <td>hamming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sprekende film maar | de film ziet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greta</td>\n",
       "      <td>w1</td>\n",
       "      <td>w2</td>\n",
       "      <td>2</td>\n",
       "      <td>['rol', 'van', 'brenn', 'vertolkte']</td>\n",
       "      <td>['rol', 'brenn', 'vertolkte']</td>\n",
       "      <td>rol van greta brenn vertolkte</td>\n",
       "      <td>['rol', 'greta', 'brenn', 'vertolkte']</td>\n",
       "      <td>[2834, 5]</td>\n",
       "      <td>['niet', 'dat', 'brenn', 'de']</td>\n",
       "      <td>['brenn']</td>\n",
       "      <td>niet dat greta brenn de</td>\n",
       "      <td>['greta', 'brenn']</td>\n",
       "      <td>[2897, 5]</td>\n",
       "      <td>hamming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rol van greta brenn vertolkte | niet dat greta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_token source target  context_size  \\\n",
       "0        greta     w1     w4             3   \n",
       "1      publiek     w1     w3             3   \n",
       "2   versiering     w1     w3             3   \n",
       "3         film     w1     w2             1   \n",
       "4        greta     w1     w2             2   \n",
       "\n",
       "                                source_context_words  \\\n",
       "0  ['eerlijk', 'interieur', 'van', 'brenns', 'hui...   \n",
       "1  ['heeft', 'omdat', 'uw', 'haar', 'niet', 'aans...   \n",
       "2  ['en', 'tevens', 'alle', 'vermijdt', 'want', '...   \n",
       "3                              ['sprekende', 'maar']   \n",
       "4               ['rol', 'van', 'brenn', 'vertolkte']   \n",
       "\n",
       "                  source_context_words_nstopw  \\\n",
       "0  ['eerlijk', 'interieur', 'brenns', 'huis']   \n",
       "1                                ['aanstond']   \n",
       "2                      ['tevens', 'vermijdt']   \n",
       "3                               ['sprekende']   \n",
       "4               ['rol', 'brenn', 'vertolkte']   \n",
       "\n",
       "                          source_context_inline  \\\n",
       "0  eerlijk interieur van greta brenns huis daar   \n",
       "1     heeft omdat uw publiek haar niet aanstond   \n",
       "2   en tevens alle versiering vermijdt want die   \n",
       "3                           sprekende film maar   \n",
       "4                 rol van greta brenn vertolkte   \n",
       "\n",
       "                        source_context_inline_nstopw source_context_span  \\\n",
       "0  ['eerlijk', 'interieur', 'greta', 'brenns', 'h...           [2533, 5]   \n",
       "1                            ['publiek', 'aanstond']           [2701, 7]   \n",
       "2               ['tevens', 'versiering', 'vermijdt']          [1326, 10]   \n",
       "3                              ['sprekende', 'film']            [184, 4]   \n",
       "4             ['rol', 'greta', 'brenn', 'vertolkte']           [2834, 5]   \n",
       "\n",
       "                                target_context_words  \\\n",
       "0  ['de', 'rol', 'van', 'brenn', 'vertolkte', 'sp...   \n",
       "1    ['ik', 'ga', 'het', 'verwittigen', 'dar', 'er']   \n",
       "2  ['prijkten', 'als', 'goedkoope', 'en', 'ter', ...   \n",
       "3                                     ['de', 'ziet']   \n",
       "4                     ['niet', 'dat', 'brenn', 'de']   \n",
       "\n",
       "                 target_context_words_nstopw  \\\n",
       "0  ['rol', 'brenn', 'vertolkte', 'speciale']   \n",
       "1               ['ga', 'verwittigen', 'dar']   \n",
       "2   ['prijkten', 'goedkoope', 'bevordering']   \n",
       "3                                   ['ziet']   \n",
       "4                                  ['brenn']   \n",
       "\n",
       "                               target_context_inline  \\\n",
       "0          de rol van greta brenn vertolkte speciale   \n",
       "1               ik ga het publiek verwittigen dar er   \n",
       "2  prijkten als goedkoope versiering en ter bevor...   \n",
       "3                                       de film ziet   \n",
       "4                            niet dat greta brenn de   \n",
       "\n",
       "                        target_context_inline_nstopw target_context_span  \\\n",
       "0  ['rol', 'greta', 'brenn', 'vertolkte', 'specia...           [2954, 5]   \n",
       "1            ['ga', 'publiek', 'verwittigen', 'dar']           [2724, 7]   \n",
       "2  ['prijkten', 'goedkoope', 'versiering', 'bevor...          [1576, 10]   \n",
       "3                                   ['film', 'ziet']           [2920, 4]   \n",
       "4                                 ['greta', 'brenn']           [2897, 5]   \n",
       "\n",
       "  similarity_metric  similarity_score  \\\n",
       "0           hamming               0.0   \n",
       "1           hamming               0.0   \n",
       "2           hamming               0.0   \n",
       "3           hamming               0.0   \n",
       "4           hamming               0.0   \n",
       "\n",
       "                             context_pair_to_compare  \n",
       "0  eerlijk interieur van greta brenns huis daar |...  \n",
       "1  heeft omdat uw publiek haar niet aanstond | ik...  \n",
       "2  en tevens alle versiering vermijdt want die | ...  \n",
       "3                 sprekende film maar | de film ziet  \n",
       "4  rol van greta brenn vertolkte | niet dat greta...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate and save representative sample to file\n",
    "error_tolerance = 0.15\n",
    "stratification_variable_column = 'similarity_score'\n",
    "\n",
    "for data_file in data_files:\n",
    "    print(data_file)\n",
    "    print()\n",
    "    \n",
    "    df = pd.read_csv(\"data/results/syntactic/\" + data_file + \".csv\")\n",
    "    sample = get_sample(df, error_tolerance, stratification_variable_column)\n",
    "    composite_samples.append(sample)\n",
    "    \n",
    "final_sample = pd.concat(composite_samples, ignore_index=True)\n",
    "final_sample.to_csv('data/results/syntactic/representative-sample.csv')\n",
    "final_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f6e26-f753-4952-8785-3af13b018579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hamming_df = df[df['similarity_metric'] == 'hamming']\n",
    "# # hamming_df_low.loc[(hamming_df_low['context_size'] <= 3) & (df_nonexact_matches['similarity_score'] <= 0.25)]\n",
    "# hamming_df_low_context_size = df[df['context_size'] <= 3]\n",
    "# hamming_df_medium_context_size = df.loc[(df['context_size'] > 3) & (df['context_size'] <= 6)]\n",
    "# hamming_df_high_context_size = df[df['context_size'] > 6]\n",
    "# print(len(hamming_df_low_context_size))\n",
    "# print(len(hamming_df_medium_context_size))\n",
    "# print(len(hamming_df_high_context_size))\n",
    "# print()\n",
    "# # remove 't' anomaly\n",
    "# hamming_df_low_context_size = hamming_df_low_context_size[hamming_df_low_context_size['source_token'] != 't']\n",
    "# print(len(hamming_df_low_context_size))\n",
    "# hamming_df_medium_context_size = hamming_df_medium_context_size[hamming_df_medium_context_size['source_token'] != 't']\n",
    "# print(len(hamming_df_medium_context_size))\n",
    "# hamming_df_high_context_size = hamming_df_high_context_size[hamming_df_high_context_size['source_token'] != 't']\n",
    "# print(len(hamming_df_high_context_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015708cc-5548-4a81-9d34-ddf8047cef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_df_low_context_size[\"context_pair_to_compare\"] = hamming_df_low_context_size[\"source_context_inline\"] + ' | ' + hamming_df_low_context_size[\"target_context_inline\"]\n",
    "# hamming_df_medium_context_size[\"context_pair_to_compare\"] = hamming_df_medium_context_size[\"source_context_inline\"] + ' | ' + hamming_df_medium_context_size[\"target_context_inline\"]\n",
    "# hamming_df_high_context_size[\"context_pair_to_compare\"] = hamming_df_high_context_size[\"source_context_inline\"] + ' | ' + hamming_df_high_context_size[\"target_context_inline\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d24cfb-d9bb-4288-ad7c-6fd47a8328b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_df_low_context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4d804-5710-4c9a-a1ca-8d846a1ddeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hamming_df_low_context_size['context_pair_to_compare'].nunique())\n",
    "# print(hamming_df_medium_context_size['context_pair_to_compare'].nunique())\n",
    "# print(hamming_df_high_context_size['context_pair_to_compare'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04db76-4b23-45e1-86a1-ab06542a46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sample(population_df, error_tolerance, stratification_variable):\n",
    "#     # Use Slovin's formula for sample size: n = N / (1 + Ne2)\n",
    "#     sample_size = len(population_df) / (1 + (len(population_df)*(error_tolerance ** 2)))\n",
    "#     sample_proportion = sample_size/len(population_df)\n",
    "#     print('sample size: ', sample_size)\n",
    "#     print('sample proportion: ', sample_proportion)\n",
    "#     # Perform stratified sampling according to similarity score\n",
    "#     sample = population_df.groupby(stratification_variable, group_keys=False).apply(lambda x: x.sample(frac=sample_proportion))\n",
    "#     return sample\n",
    "\n",
    "# error_tolerance = 0.2\n",
    "# stratification_variable_column = 'similarity_score'\n",
    "# low_context_size_sample = get_sample(hamming_df_low_context_size, error_tolerance, stratification_variable_column)\n",
    "# medium_context_size_sample = get_sample(hamming_df_medium_context_size, error_tolerance, stratification_variable_column)\n",
    "# high_context_size_sample = get_sample(hamming_df_high_context_size, error_tolerance, stratification_variable_column)\n",
    "\n",
    "# print('low cxt sample size:', len(low_context_size_sample))\n",
    "# print('medium cxt sample size:', len(low_context_size_sample))\n",
    "# print('high cxt sample size:', len(low_context_size_sample))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc139d87-c12f-42b4-8a41-0ad962542d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    " \n",
    "# # Function to create the random binary string\n",
    "# def rand_key(p):\n",
    "   \n",
    "#     # Variable to store the list\n",
    "#     key1 = []\n",
    " \n",
    "#     # Loop to find the string\n",
    "#     # of desired length\n",
    "#     for i in range(p):\n",
    "         \n",
    "#         # randint function to generate\n",
    "#         # 0, 1 randomly and converting\n",
    "#         # the result into str\n",
    "#         temp = str(random.randint(0, 2))\n",
    " \n",
    "#         # Concatenation the random 0, 1, 2\n",
    "#         # to the final result\n",
    "#         key1.append(temp)\n",
    "         \n",
    "#     return key1\n",
    " \n",
    "# # Driver Code\n",
    "# n = len(sample)\n",
    "# sequence = rand_key(n)\n",
    "# print(\"Desired length random binary string is: \", sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341148f0-d8fc-4d90-b727-7a685d0fe332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample['match_human_judgement'] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65a220-0104-447b-9061-8fb6c4ed7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
